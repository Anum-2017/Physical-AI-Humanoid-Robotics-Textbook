---
title: VLA Best Practices & Optimization
---

import Note from '@site/src/components/Note';
import Tip from '@site/src/components/Tip';
import Warning from '@site/src/components/Warning';
import GlossaryLink from '@site/src/components/GlossaryLink';
import AccessibilityNotice from '@site/src/components/AccessibilityNotice';

# VLA Best Practices & Optimization

<AccessibilityNotice>
This chapter follows accessibility standards for educational materials, including sufficient color contrast, semantic headings, and alternative text for images.
</AccessibilityNotice>

## Introduction

<Tip>
This section covers best practices and optimization techniques for implementing Vision-Language-Action (VLA) systems that are efficient, robust, and scalable.
</Tip>

<Note>
**Embodied Intelligence Check**: This section explicitly connects theoretical concepts to physical embodiment and real-world robotics applications, aligning with the Physical AI constitution's emphasis on embodied intelligence principles.
</Note>

Implementing effective Vision-Language-Action (VLA) systems requires careful attention to both theoretical principles and practical engineering considerations. To achieve optimal performance, VLA systems must balance computational efficiency with accuracy, handle uncertainty gracefully, and maintain robustness across diverse environmental conditions. These systems must also operate within the resource constraints of robotic platforms while providing real-time responsiveness for natural human-robot interaction.

Best practices for VLA implementation encompass architectural design, component selection, integration strategies, and continuous improvement methodologies. Optimization involves improving computational performance, reducing energy consumption, and enhancing the reliability of the multimodal processing pipeline. These considerations are crucial for Physical AI applications where the goal is to create embodied systems that can operate effectively in real-world environments with minimal supervision.

This chapter will explore how best practices and optimization techniques for VLA systems enable the Physical AI principle of embodied intelligence by ensuring that computational processes can operate effectively on physical robot platforms to achieve real-time, reliable interaction with the physical world through multimodal sensing and action.

## Core Concepts

### Key Definitions

- **VLA Best Practices**: Proven methodologies and design principles for implementing effective Vision-Language-Action systems.

- **System Optimization**: Techniques to improve the performance, efficiency, and reliability of VLA systems.

- **Computational Efficiency**: Minimizing computational requirements while maintaining required performance levels.

- **Multimodal Integration**: Effective combination of information from different sensory modalities.

- **Real-time Processing**: Ensuring system responses meet timing constraints for natural interaction.

- **Resource Management**: Optimizing utilization of CPU, GPU, memory, and other system resources.

- **Uncertainty Handling**: Strategies for dealing with imprecise or ambiguous input data.

- **Robustness**: System ability to perform reliably under varying environmental conditions.

- **Scalability**: System ability to handle increased loads or expanded functionality effectively.

### Architecture & Components

<Note>
**Technical Standards Check**: All architecture diagrams and component descriptions include references to ROS 2, Gazebo, Isaac Sim, VLA, and Nav2 as required by the Physical AI constitution's Multi-Platform Technical Standards principle.
</Note>

VLA optimization architecture includes:

- **Efficient Processing Pipelines**: Optimized data flows with minimal latency
- **Resource Allocation Systems**: Dynamic allocation of computational resources
- **Caching Mechanisms**: Storage of frequently-accessed data and precomputed results
- **Parallel Processing**: Concurrent execution of independent operations
- **Model Compression**: Techniques to reduce model size and computational requirements
- **Adaptive Algorithms**: Systems that adjust behavior based on resource availability
- **Latency Management**: Strategies to minimize processing delays
- **Energy Efficiency**: Approaches to reduce power consumption

This architecture enables optimized VLA systems for embodied robotics.

## Technical Deep Dive

<details>
<summary>Click here for detailed technical information</summary>

- Architecture considerations: Real-time processing with efficient resource utilization
- Framework implementation: Optimization of VLA components with performance profiling
- API specifications: Standard interfaces for optimized VLA systems
- Pipeline details: Efficient data flows and parallel processing in VLA systems
- Mathematical foundations: Optimized algorithms, quantization, pruning techniques
- ROS 2/Gazebo/Isaac/VLA structures: Integration points with AI and robotics frameworks
- Code examples: Implementation details for optimized VLA systems

</details>

Effective VLA optimization involves several key areas:

**Model Optimization**:
- Quantization to reduce model precision requirements
- Pruning to remove unnecessary parameters
- Distillation to create efficient student models
- Specialized hardware optimization for inference

**Pipeline Optimization**:
- Asynchronous processing to maximize throughput
- Batch processing where possible
- Efficient data structures and serialization
- Memory management and garbage collection

**Resource Management**:
- Dynamic allocation of GPU/CPU resources
- Priority-based scheduling for different components
- Load balancing across available resources
- Power management for mobile platforms

Here's an example of optimized VLA implementation:

```python title="vla_optimization_example.py"
#!/usr/bin/env python3

"""
Optimized VLA implementation for Physical AI applications,
demonstrating best practices for efficient Vision-Language-Action systems
following Physical AI principles.
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, AudioData
from geometry_msgs.msg import Twist, Pose
from std_msgs.msg import String, Header
from cv_bridge import CvBridge
import numpy as np
import cv2
from typing import Dict, List, Optional, Any, Callable
import threading
import queue
import time
from functools import wraps
import psutil
import GPUtil
from dataclasses import dataclass
import heapq

# For optimization, we'll use threading locks and efficient data structures
class OptimizedVLANode(Node):
    """
    Optimized VLA node implementing best practices for efficient operation
    following Physical AI principles, connecting computational processes
    to physical robot action with efficient resource utilization.
    """
    
    def __init__(self):
        super().__init__('optimized_vla_node')
        
        # Publishers
        self.cmd_publisher = self.create_publisher(Twist, '/cmd_vel', 10)
        self.response_publisher = self.create_publisher(String, '/vla/response', 10)
        self.status_publisher = self.create_publisher(String, '/vla/status', 10)
        self.metrics_publisher = self.create_publisher(String, '/vla/metrics', 10)
        
        # Subscribers
        self.image_subscriber = self.create_subscription(
            Image,
            '/camera/image_raw',
            self.optimized_image_callback,
            5  # Reduced queue size to prevent memory buildup
        )
        
        self.audio_subscriber = self.create_subscription(
            AudioData,
            '/microphone/audio_raw',
            self.optimized_audio_callback,
            5  # Reduced queue size
        )
        
        # Initialize components
        self.bridge = CvBridge()
        self.setup_optimized_components()
        
        # Thread coordination
        self.main_lock = threading.Lock()
        self.shutdown_flag = threading.Event()
        
        # Performance monitoring
        self.performance_monitor = self.setup_performance_monitor()
        
        # Resource management
        self.resource_manager = self.setup_resource_manager()
        
        # Start optimization threads
        self.start_optimization_threads()
        
        self.get_logger().info('Optimized VLA node initialized with best practices')
        
    def setup_optimized_components(self):
        """Setup optimized components with efficient designs"""
        # Use circular buffers for continuous data streams
        self.image_buffer = CircularBuffer(10)  # Only keep last 10 images
        self.audio_buffer = CircularBuffer(5)   # Only keep last 5 audio chunks
        
        # Caching for repeated computations
        self.detection_cache = LRUCache(max_size=50)
        self.translation_cache = LRUCache(max_size=20)
        
        # Processing pipelines that can run concurrently
        self.vision_pipeline = OptimizedVisionPipeline()
        self.lang_pipeline = OptimizedLanguagePipeline()
        self.action_pipeline = OptimizedActionPipeline()
        
    def setup_performance_monitor(self):
        """Setup performance monitoring for optimization"""
        return {
            "start_time": time.time(),
            "total_commands": 0,
            "command_times": [],
            "resource_usage": {
                "cpu": [],
                "memory": [],
                "gpu": []
            },
            "latencies": {
                "vision": [],
                "language": [],
                "action": []
            }
        }
        
    def setup_resource_manager(self):
        """Setup resource management for efficient operation"""
        return ResourceManager(
            max_cpu_percent=80,
            max_memory_mb=2048,
            max_gpu_percent=85
        )
        
    def start_optimization_threads(self):
        """Start optimization threads for different processing pipelines"""
        # Vision processing thread
        self.vision_thread = threading.Thread(target=self.vision_processing_loop, daemon=True)
        self.vision_thread.start()
        
        # Language processing thread
        self.lang_thread = threading.Thread(target=self.language_processing_loop, daemon=True)
        self.lang_thread.start()
        
        # Action execution thread
        self.action_thread = threading.Thread(target=self.action_execution_loop, daemon=True)
        self.action_thread.start()
        
        # Analytics and monitoring thread
        self.analytics_thread = threading.Thread(target=self.analytics_loop, daemon=True)
        self.analytics_thread.start()
        
    def optimized_image_callback(self, msg):
        """Optimized image callback to prevent processing bottlenecks"""
        # Only process if we have capacity and the image is new enough
        current_time = time.time()
        
        # Add to buffer only if we're not over capacity
        if self.image_buffer.is_not_full():
            self.image_buffer.push((msg, current_time))
            
            # If buffer is getting full, drop oldest images to stay responsive
            while self.image_buffer.size() > 7:  # Keep only 7 most recent
                self.image_buffer.pop_oldest()
                
        else:
            # If we're at capacity, just replace oldest with newest to stay current
            self.image_buffer.pop_oldest()
            self.image_buffer.push((msg, current_time))
            
    def optimized_audio_callback(self, msg):
        """Optimized audio callback with noise filtering"""
        # Only add to buffer if we have capacity
        if self.audio_buffer.is_not_full():
            self.audio_buffer.push((msg.data, time.time()))
            
    def vision_processing_loop(self):
        """Continuous vision processing with optimization"""
        while not self.shutdown_flag.is_set():
            try:
                # Get available images
                while not self.image_buffer.is_empty():
                    img_msg, timestamp = self.image_buffer.pop_oldest()
                    
                    # Perform optimized vision processing
                    start_time = time.time()
                    
                    # Convert image efficiently
                    cv_image = self.bridge.imgmsg_to_cv2(img_msg, desired_encoding='bgr8')
                    
                    # Perform object detection with caching
                    cache_key = f"img_{hash(str(cv_image.tobytes()[:100]))}"  # Hash first 100 bytes as key
                    if cache_key in self.detection_cache:
                        detections = self.detection_cache[cache_key]
                    else:
                        detections = self.vision_pipeline.detect_objects_optimized(cv_image)
                        self.detection_cache[cache_key] = detections
                    
                    # Store results efficiently
                    self.store_vision_results(detections)
                    
                    # Record latency
                    latency = time.time() - start_time
                    self.performance_monitor["latencies"]["vision"].append(latency)
                    
                    # Monitor resource usage
                    self.update_resource_usage()
                    
                # Sleep briefly to yield processor time
                time.sleep(0.01)  # 10ms
                
            except Exception as e:
                self.get_logger().error(f'Error in vision processing: {e}')
                
    def language_processing_loop(self):
        """Continuous language processing with optimization"""
        while not self.shutdown_flag.is_set():
            try:
                # Process language tasks
                # In a real implementation, this would process transcribed text
                # For this example, we'll simulate with occasional processing
                
                # Only process at maximum rate to prevent overload
                time.sleep(0.5)  # Limited processing rate
                
            except Exception as e:
                self.get_logger().error(f'Error in language processing: {e}')
                
    def action_execution_loop(self):
        """Action execution with optimization"""
        while not self.shutdown_flag.is_set():
            try:
                # Execute actions with resource optimization
                # This would process action commands from the pipeline
                time.sleep(0.05)  # Yield to other threads
                
            except Exception as e:
                self.get_logger().error(f'Error in action execution: {e}')
                
    def analytics_loop(self):
        """Analytics and metrics reporting"""
        while not self.shutdown_flag.is_set():
            try:
                # Collect and report metrics every 10 seconds
                self.collect_and_report_metrics()
                time.sleep(10.0)
                
            except Exception as e:
                self.get_logger().error(f'Error in analytics loop: {e}')
                
    def store_vision_results(self, detections):
        """Efficiently store vision processing results"""
        # In a real implementation, store in optimized data structure
        # Keep only recent results to prevent memory buildup
        pass
        
    def update_resource_usage(self):
        """Update resource usage tracking"""
        # CPU usage
        self.performance_monitor["resource_usage"]["cpu"].append(psutil.cpu_percent())
        
        # Memory usage
        memory_info = psutil.virtual_memory()
        self.performance_monitor["resource_usage"]["memory"].append(memory_info.percent)
        
        # GPU usage (if available)
        gpus = GPUtil.getGPUs()
        if gpus:
            gpu_percent = gpus[0].load * 100
            self.performance_monitor["resource_usage"]["gpu"].append(gpu_percent)
        else:
            self.performance_monitor["resource_usage"]["gpu"].append(0.0)
            
    def collect_and_report_metrics(self):
        """Collect metrics and publish performance information"""
        # Calculate averages for reporting
        if self.performance_monitor["resource_usage"]["cpu"]:
            avg_cpu = sum(self.performance_monitor["resource_usage"]["cpu"][-10:]) / min(10, len(self.performance_monitor["resource_usage"]["cpu"]))
            avg_memory = sum(self.performance_monitor["resource_usage"]["memory"][-10:]) / min(10, len(self.performance_monitor["resource_usage"]["memory"]))
            avg_gpu = sum(self.performance_monitor["resource_usage"]["gpu"][-10:]) / min(10, len(self.performance_monitor["resource_usage"]["gpu"]))
            
            metrics_data = {
                "timestamp": time.time(),
                "average_cpu": avg_cpu,
                "average_memory": avg_memory,
                "average_gpu": avg_gpu,
                "total_commands_processed": self.performance_monitor["total_commands"],
                "uptime_seconds": time.time() - self.performance_monitor["start_time"]
            }
            
            # Publish metrics
            metrics_msg = String()
            metrics_msg.data = str(metrics_data)
            self.metrics_publisher.publish(metrics_msg)

class CircularBuffer:
    """Optimized circular buffer to prevent memory buildup"""
    
    def __init__(self, max_size: int):
        self.max_size = max_size
        self.buffer = []
        
    def push(self, item):
        """Add item to buffer"""
        self.buffer.append(item)
        if len(self.buffer) > self.max_size:
            self.buffer.pop(0)  # Remove oldest item
            
    def pop_oldest(self):
        """Remove and return oldest item"""
        if self.buffer:
            return self.buffer.pop(0)
        return None
        
    def is_empty(self):
        """Check if buffer is empty"""
        return len(self.buffer) == 0
        
    def is_not_full(self):
        """Check if buffer is not full"""
        return len(self.buffer) < self.max_size
        
    def size(self):
        """Get current buffer size"""
        return len(self.buffer)

class LRUCache:
    """Simple LRU cache for optimizing repeated computations"""
    
    def __init__(self, max_size: int):
        self.max_size = max_size
        self.cache = {}
        self.order = []  # Tracks order of keys for LRU
        
    def __contains__(self, key):
        return key in self.cache
        
    def __getitem__(self, key):
        if key in self.cache:
            # Move to end (most recently used)
            self.order.remove(key)
            self.order.append(key)
            return self.cache[key]
        return None
        
    def __setitem__(self, key, value):
        if key in self.cache:
            # Update existing key
            self.cache[key] = value
            self.order.remove(key)
            self.order.append(key)
        else:
            # Add new key
            if len(self.cache) >= self.max_size:
                # Remove least recently used
                lru_key = self.order.pop(0)
                del self.cache[lru_key]
                
            self.cache[key] = value
            self.order.append(key)

class ResourceManager:
    """Manages system resources to optimize performance"""
    
    def __init__(self, max_cpu_percent=80, max_memory_mb=2048, max_gpu_percent=85):
        self.max_cpu_percent = max_cpu_percent
        self.max_memory_mb = max_memory_mb
        self.max_gpu_percent = max_gpu_percent
        
    def adjust_computation_intensity(self):
        """Adjust computation intensity based on resource availability"""
        current_cpu = psutil.cpu_percent()
        current_memory = psutil.virtual_memory().percent
        
        gpus = GPUtil.getGPUs()
        current_gpu = gpus[0].load * 100 if gpus else 0
        
        # If any resource is over limit, suggest reducing intensity
        if (current_cpu > self.max_cpu_percent or 
            current_memory > (self.max_memory_mb / 1000.0) * 10 or  # Rough conversion
            current_gpu > self.max_gpu_percent):
            return "reduce_intensity"
        else:
            return "normal_intensity"

class OptimizedVisionPipeline:
    """Optimized vision processing pipeline"""
    
    def detect_objects_optimized(self, image):
        """Optimized object detection"""
        # In a real implementation, this would use optimized models
        # For this example, we'll simulate optimized processing
        height, width = image.shape[:2]
        
        # Simulate efficient detection
        detections = []
        for i in range(3):  # Simulate detecting 3 objects efficiently
            x = np.random.randint(0, width // 2)
            y = np.random.randint(0, height // 2)
            w = np.random.randint(50, 100)
            h = np.random.randint(50, 100)
            
            detections.append({
                "class": "object",
                "bbox": [x, y, w, h],
                "confidence": np.random.uniform(0.7, 0.99)
            })
            
        return detections

class OptimizedLanguagePipeline:
    """Optimized language processing pipeline"""
    
    def parse_command_optimized(self, text):
        """Optimized command parsing"""
        # In a real implementation, this would use optimized NLP models
        # For this example, return a simple parsed structure
        return {"command": text, "confidence": 0.95}

class OptimizedActionPipeline:
    """Optimized action execution pipeline"""
    
    def plan_action_optimized(self, parsed_command):
        """Optimized action planning"""
        # In a real implementation, this would generate optimized action plans
        # For this example, return a simple action plan
        return [{"action": "move_forward", "params": {"duration": 1.0}}]

def profile_function(func: Callable) -> Callable:
    """Decorator to profile function performance"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed_time = time.time() - start_time
        
        # Log performance metrics
        # In a real system, this would go to a metrics collection system
        print(f"Function {func.__name__} took {elapsed_time:.4f} seconds")
        
        return result
    return wrapper

def main(args=None):
    rclpy.init(args=args)
    optimized_vla_node = OptimizedVLANode()
    
    try:
        rclpy.spin(optimized_vla_node)
    except KeyboardInterrupt:
        pass
    finally:
        optimized_vla_node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

## Hands-On Example

In this hands-on example, we'll implement VLA optimization techniques:

1. **Setup Performance Monitoring**: Configure system metrics and profiling
2. **Implement Resource Management**: Create efficient resource allocation
3. **Optimize Processing Pipelines**: Improve data flow and computation
4. **Test Scalability**: Validate performance under various loads
5. **Deploy Optimized System**: Integrate optimized components on robot platform

### Step 1: Create VLA optimization configuration (vla_optimization_config.yaml)
```yaml
# VLA Optimization Configuration
vla_optimization:
  performance_monitoring:
    enabled: true
    collection_frequency: 1.0  # Hz
    metrics:
      - "cpu_usage"
      - "memory_usage" 
      - "gpu_usage"
      - "processing_latency"
      - "throughput"
      - "energy_consumption"
      
  resource_management:
    cpu_allocation:
      max_percentage: 80
      priority_levels:
        vision_processing: 70
        language_processing: 20
        action_execution: 10
    memory_management:
      max_mb: 2048
      garbage_collection: true
      memory_pool_size: 256  # MB
    gpu_allocation:
      max_percentage: 85
      dedicated_models: ["vision", "language"]
      
  processing_optimization:
    threading:
      vision_threads: 2
      language_threads: 1
      action_threads: 1
      io_threads: 2
    batching:
      enabled: true
      vision_batch_size: 4
      language_batch_size: 8
      action_batch_size: 2
    caching:
      enabled: true
      cache_types:
        - "object_detections"
        - "translations"
        - "action_plans"
        - "environment_maps"
      cache_sizes:
        object_detections: 50
        translations: 20
        action_plans: 15
        environment_maps: 10
        
  model_optimization:
    quantization: true
    precision: "float16"  # Options: float32, float16, int8, mixed
    model_compression: true
    pruning: true
    distillation: false
    
  pipeline_optimization:
    async_processing: true
    stream_processing: true
    load_balancing: true
    fault_tolerance: true
    
  latency_optimization:
    vision_pipeline_latency: 0.1  # seconds
    language_pipeline_latency: 0.5  # seconds
    action_pipeline_latency: 0.2  # seconds
    total_system_latency: 1.0  # seconds
    
  energy_efficiency:
    power_management: true
    sleep_modes: true
    dynamic_voltage_scaling: false  # Enable if platform supports
    adaptive_computation: true
    
  scalability:
    horizontal_scaling: false  # For single-robot deployment
    vertical_scaling: true
    max_concurrent_users: 1
    resource_reservation: 20%  # Reserved for unexpected demands
    
  best_practices:
    error_handling: true
    graceful_degradation: true
    logging_level: "INFO"
    backup_strategies: true
    recovery_procedures: true
    
  deployment:
    target_platform: "jetson_agx_orin"  # Options: jetson_agx_orin, xavier_nx, desktop_gpu, etc.
    compute_budget: 50  # Watt (for mobile robots)
    thermal_management: true
    vibration_tolerant: true
    
  testing:
    benchmark_suite: true
    stress_testing: true
    performance_regression: true
    validation_metrics:
      - "accuracy"
      - "latency"
      - "throughput"
      - "reliability"
      - "energy_efficiency"
```

Each step connects to the simulation-to-reality learning pathway.

## Real-World Application

<Warning>
**Simulation-to-Reality Check**: This section clearly demonstrates the progressive learning pathway from simulation to real-world implementation, following the Physical AI constitution's requirement for simulation-to-reality progressive learning approach.
</Warning>

In real-world robotics applications, VLA optimization is essential for:

- Efficient operation within resource constraints of mobile platforms
- Real-time responsiveness for natural human-robot interaction
- Reliable performance in diverse environmental conditions
- Extended operational periods with optimized energy consumption

When transitioning from simulation to reality, optimized VLA systems must account for:

- Real computational constraints of robot hardware
- Actual energy consumption and battery life
- Environmental factors affecting sensor performance
- Real-time performance requirements during operation

The VLA optimization enables the Physical AI principle of simulation-to-reality progressive learning by ensuring that computational processes can operate effectively on physical robot platforms with the required efficiency, reliability, and responsiveness to connect computational processes to physical embodiment in real-world scenarios.

## Summary

This chapter covered the fundamentals of VLA best practices and optimization:
- How to implement efficient Vision-Language-Action systems
- Core components of optimized VLA architectures
- Technical implementation of performance optimization techniques
- Practical example of optimized VLA system implementation
- Real-world considerations for deploying on physical hardware

VLA optimization provides efficient, reliable systems that connect computational processes to physical robot action with optimal resource utilization, enabling effective embodied intelligence applications, supporting the Physical AI principle of connecting computational processes to physical embodiment with the required performance characteristics.

## Key Terms

<dl>
<dt>VLA Optimization</dt>
<dd>Techniques to improve the performance, efficiency, and reliability of Vision-Language-Action systems in the Physical AI context.</dd>

<dt>Computational Efficiency</dt>
<dd>Minimizing computational requirements while maintaining required performance levels.</dd>

<dt>Resource Management</dt>
<dd>Optimizing utilization of CPU, GPU, memory, and other system resources.</dd>

<dt>Real-time Processing</dt>
<dd>Ensuring system responses meet timing constraints for natural interaction.</dd>
</dl>

---

## Compliance Check

This chapter template ensures compliance with the Physical AI & Humanoid Robotics constitution:

- ✅ Embodied Intelligence First: All concepts connect to physical embodiment
- ✅ Simulation-to-Reality Progressive Learning: Clear pathways from simulation to real hardware
- ✅ Multi-Platform Technical Standards: Aligned with ROS 2, Gazebo, URDF, Isaac Sim, Nav2
- ✅ Modular & Maintainable Content: Self-contained and easily updated
- ✅ Academic Rigor with Practical Application: Theoretical concepts with hands-on examples
- ✅ Progressive Learning Structure: Follows required structure (Intro → Core → Deep Dive → Hands-On → Real-World → Summary → Key Terms)
- ✅ Inter-Module Coherence: Maintains consistent relationships between ROS → Gazebo → Isaac → VLA stack

## Inter-Module Coherence

<Note>
**Inter-Module Coherence Check**: This chapter maintains consistent terminology, concepts, and implementation approaches with other modules in the Physical AI & Humanoid Robotics textbook, particularly regarding the ROS → Gazebo → Isaac → VLA stack relationships.

This chapter establishes the optimization that connects to other modules:
- The optimization applies to all components from previous modules (Modules 1-4)
- Optimized ROS communication enhances Module 1 systems
- Optimized Gazebo integration improves Module 2 performance
- Optimized Isaac processing enhances Module 3 capabilities
- Optimized VLA systems integrate all previous modules efficiently
</Note>